{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualising the network lossNOTES.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmCHcwKs6rd",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing the network loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PzCCniVwNTdp",
        "colab": {}
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fQLW-HL7_0pT",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PCJzXv0OK1Bs",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqMqFbIVrbFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FMNIST(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x\n",
        "\n",
        "model = FMNIST()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67eZUNEM5b7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJLzWi0UqGWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 30\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    cum_loss = 0\n",
        "    \n",
        "    for batch, (images, labels) in enumerate(trainloader,1):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        cum_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(cum_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {cum_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (images, labels) in enumerate(testloader,1):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        logps = model(images)\n",
        "        batch_loss = criterion(logps, labels)        \n",
        "        test_loss += batch_loss.item()\n",
        "        \n",
        "        output = torch.exp(logps)\n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "    \n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89a8FdTi-cNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgyMHm2Pvx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFryN0JM8G6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}