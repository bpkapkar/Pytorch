{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_03_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gXmCHcwKs6rd"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PzCCniVwNTdp",
        "colab": {}
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PCJzXv0OK1Bs",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rqMqFbIVrbFH",
        "colab": {}
      },
      "source": [
        "class FMNIST(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x\n",
        "\n",
        "model = FMNIST()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNNyI5YRZ7H1",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    cum_loss = 0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        cum_loss += loss.item()\n",
        "     \n",
        "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWYw7ZOzsS8U",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(testloader))\n",
        "\n",
        "test_image_id = 0 \n",
        "img = images[test_image_id].view(1, 784) \n",
        "\n",
        "with torch.no_grad():\n",
        "    logps = model(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRjoEDSqY8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ps = torch.exp(logps)\n",
        "ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpP_RLV-qkc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nps = ps.numpy()[0]\n",
        "nps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBf23XrtqrB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boots']\n",
        "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
        "plt.bar(np.arange(10), nps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7gY5hARpOp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def denormalize(tensor):\n",
        "  tensor = tensor*0.5 + 0.5\n",
        "  return tensor\n",
        "  \n",
        "img = img.view(28,-1)\n",
        "img = denormalize(img)\n",
        "plt.imshow(img,cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxTiil7cXOAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    cnt = 0\n",
        "    for images, labels in testloader:\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        print(output)\n",
        "        cnt+=1\n",
        "        \n",
        "        if cnt > 0:\n",
        "          break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ij_wa7paveM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for images, labels in testloader:\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyxadgAyiRqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojLPwZLdi3OX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred == labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6V-3r9n-iCMb",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #set_trace()\n",
        "    for images, labels in testloader:\n",
        "        \n",
        "        logps = model(images)\n",
        "        output = torch.exp(logps)\n",
        "        \n",
        "        pred = torch.argmax(output, 1)\n",
        "        total += labels.size(0)\n",
        "        num_correct += (pred == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the 10000 test images: {num_correct * 100 / total}% ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VNQH0g6F8xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}